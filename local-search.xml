<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>H264编码原理</title>
    <link href="/2021/06/20/H264%E7%BC%96%E7%A0%81%E5%8E%9F%E7%90%86/"/>
    <url>/2021/06/20/H264%E7%BC%96%E7%A0%81%E5%8E%9F%E7%90%86/</url>
    
    <content type="html"><![CDATA[<hr style=" border:solid; width:100px; height:1px;" color=#000000 size=1"><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>本文将从H264的发展历史开始，详细介绍H264编码的原理以及涉及的知识点，作为个人学习的总结。</p><h1 id="一、H264概述"><a href="#一、H264概述" class="headerlink" title="一、H264概述"></a>一、H264概述</h1><p>对于未入门的人可能会对命名有点疑惑,比如对于H.264, 还会看到有些标签还写成MPEG-4/AVC，这是什么原因呢？</p><p>可以简单理解为视频编码格式的制定主要有两大门派，本来H.26X系统由ITU-T主导开发, MPEG系列由ISO主导开发，然后两大门派合作开发了H.264 和H.265 , H.264,H.265是ITU组织对着两种编码格式的命名, MPEG-4/AVC ,MPEG-4/HEVC是ISO组织对这两种编码格式的命名。以下的图片展示了视频编码格式的发展。<br><img src="https://img-blog.csdnimg.cn/20210619163700484.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">   </p><h1 id="二、H264压缩码率和GOP"><a href="#二、H264压缩码率和GOP" class="headerlink" title="二、H264压缩码率和GOP"></a>二、H264压缩码率和GOP</h1><h2 id="压缩比和码率设置"><a href="#压缩比和码率设置" class="headerlink" title="压缩比和码率设置"></a>压缩比和码率设置</h2><p>原始YUV数据像素格式为YUV420，分辨率为640x480，帧率为15帧，计算得到原始视频数据码流为55Mbps左右，而H264建议的码流大小为500kbps，结果显示，H264压缩比达到1/100左右！</p><p>具体码流大小的设定可参考声网的技术文档，如下图，链接<a href="https://docs.agora.io/cn/Video/video_profile_android?platform=Android">声网文档资料</a><br><img src="https://img-blog.csdnimg.cn/20210619165835831.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="GOP和I帧，P帧，B帧"><a href="#GOP和I帧，P帧，B帧" class="headerlink" title="GOP和I帧，P帧，B帧"></a>GOP和I帧，P帧，B帧</h2><p>GOP即Group of picture（图像组），可以理解为GOP是一组连续的图像，并且他们之间相关性很大，在一组GOP中包含I帧，B帧和P帧。<br>对每一帧的类型又可以划分为：</p><p>·I帧：关键帧，采用帧内压缩技术。<br>·P帧：向前参考帧，在压缩时，只参考前面已经处理的帧。采用帧压缩技术。大小大约为I帧的一半。<br>·B帧：双向参考帧，在压缩时，它即参考前而的帧，又参考它后面的帧。采用帧间压缩技术。大小约为I帧大小的1/4。</p><p>短视频采用很多b帧和p帧，I帧很少，相应的GOP序列很长，这就是在弱网络环境下依然可以播放流畅的原因。</p><p><img src="https://img-blog.csdnimg.cn/20210619160939925.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p><strong>IDR帧是什么？</strong></p><p>IDR帧为解码器立刻刷新帧，每当遇到IDR帧时，解码器会立刻清空参考buffer中的内容，IDR帧的作用是使错误不致传播,从IDR帧开始,重新算一个新的序列开始编码，IDR帧可以随机访问，而I帧不具有随机访问的能力，也就说IDR帧是一种特殊的I帧，但I帧不一定是IDR帧。</p><p><font color='red'> 疑问：既然如此，那I帧还有存在的必要吗？为什么不都叫IDR帧呢？ </font></p><p>通过查阅资料发现，上图展示的GOP仅仅是一种情况而已，对于存在大量帧的GOP，如果仅依赖第一个IDR帧，则可能会造成解码出与原始图像差异较大的情况；编码器会在适当的时候（如场景切换）强制插入一个I帧来提高解码图像的质量。<br>在每个IDR帧前面都有两个帧，SPS和PPS。（在编解码流程时候再具体分析）<br><strong>·SPS（Sequence Parameter Set）</strong><br>序列参数集，作用于一串连续的视频图像。如seq_parameter_set_id，帧数以及POC（picture order count）的约束、参考帧数目、解码图像尺寸和帧场编码模式选择标识等<br><strong>·PPS（Picture Parameter Set）</strong><br>图像参数集，作用于视频序列中的图像。如pic_parameter_set_id、熵编码模式选择标识、片组数目、初始量化参数和去方块铝箔系数调整标识等。</p><p><strong>H264编码规则</strong><br>有了上述的知识，对于I帧，P帧和B帧就有了一个认识，即是什么，那为什么呢，为什么编码器要将他们分为I帧P帧和B帧来编码呢，编码器是根据什么规则来确定他们是I帧P帧和B帧的呢？</p><p>在相邻几个帧中，一般有差别的像素只有10%以内的点亮度差值变化不超过2%，而色度变化只有1%以内，所以对于一段变化不大的图像画面，我们可以先编码出一个完整的图像帧，即I帧为完整的图像帧。<br>与I帧相似程度高达95%以上的帧编码为B帧，相似程度70%编码成P帧，利用libx264这个工具帮我们完成。</p><h1 id="二、H264压缩技术"><a href="#二、H264压缩技术" class="headerlink" title="二、H264压缩技术"></a>二、H264压缩技术</h1><p>H264压缩技术主要采用了以下几种方法对视频数据进行压缩。包括：</p><p>·帧内预测压缩，解决的是空域数据冗余问题。<br>·帧间预测压缩（运动估计与补偿），解决的是时域数据冗余问题。<br>·无损压缩，利用哈夫曼编码的原理对视频进一步压缩，得到更大的压缩比。</p><h2 id="1-H264中的宏块划分"><a href="#1-H264中的宏块划分" class="headerlink" title="1.H264中的宏块划分"></a>1.H264中的宏块划分</h2><p>·宏块是视频压缩的操作的基本单元，无论是帧内压缩，都以宏块为单位<br>H264宏块划分，以下面这幅原始图片为例：<br><img src="https://img-blog.csdnimg.cn/20210619161654562.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>将上面的图片可以划分成很多的宏块<br><img src="https://img-blog.csdnimg.cn/20210619225136202.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>H264的16x16的宏块可以继续划分，划分为更小的子块<br><img src="https://img-blog.csdnimg.cn/20210619230408649.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20210619230637791.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="2-帧内压缩（I帧）"><a href="#2-帧内压缩（I帧）" class="headerlink" title="2.帧内压缩（I帧）"></a>2.帧内压缩（I帧）</h2><p>帧内压缩是利用一个帧内相邻像素差别不大的特点，所以可以进行<strong>宏块预测</strong>，人们对亮度的敏感度超过色度，YUV数据天然就可以将亮度与色度分开。</p><p>下图展示了帧内预测的9中模式和帧内预测的结果<br><img src="https://img-blog.csdnimg.cn/20210619231211562.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>具体的预测模式的如下图所示，根据已知的宏块信息去推测下未知的宏块信息。<br><img src="https://img-blog.csdnimg.cn/20210619231431442.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>不同模式预测的结果是有差异性的</p><p><img src="https://img-blog.csdnimg.cn/20210619231554150.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>依据与原始数据最相似的结果来确定预测的模式，通过宏块的预测可以节省数据存储的空间，但是预测的结果与原图并不是100%相同的，如图所示</p><p><img src="https://img-blog.csdnimg.cn/20210619231810822.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>将原图与预测结果进行差值计算，得到残差值，也就是说，预测结果+残差值=原图<br><img src="https://img-blog.csdnimg.cn/20210619231939225.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>对预测结果和残差值进行进一步压缩，是小于原始图像的，这就达到了帧内压缩的目的。<br><img src="https://img-blog.csdnimg.cn/20210619232219719.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h2 id="3-帧间压缩（P帧，B帧）"><a href="#3-帧间压缩（P帧，B帧）" class="headerlink" title="3.帧间压缩（P帧，B帧）"></a>3.帧间压缩（P帧，B帧）</h2><p>帧间压缩是利用一个GOP内相邻帧强相关的特点，通过后面的帧参考前面的帧的方法，通过宏块匹配的方法，找到宏块的运动矢量，如下图所示的GOP中不同帧之间的差别就是小球的位置。<br><img src="https://img-blog.csdnimg.cn/20210619235100947.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>对于相邻帧之间的差别，通过宏块的查找，也就是运动估计，得到每一帧的运动矢量，如下图右边所示，只需存储很少的数据量即可得到每一帧之间的差别，可以根据参考帧还原回原始的图像</p><p><img src="https://img-blog.csdnimg.cn/20210619235446606.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>同样地，在运动估计的宏块查找过程中，并不是100%的能找到一样的宏块，因此存在一定的误差，因此记录下残差值，将运动矢量+残差值即可解码得到完整的图像<br><img src="https://img-blog.csdnimg.cn/20210619235743454.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><font color='red'> 在直播或者音视频通话中，会出现视频画屏或者卡顿的的情况，这是什么原因呢？</font></p><p>花屏的原因：GOP中有帧丢失，残差值和运动矢量丢失，造成了模糊的数据，解码端图像发生了错误，因此会出现马赛克（花屏）。</p><p>卡顿的原因：为了避免花屏的发生，当发现有帧丢失的时候，就丢弃GOP中所有的帧，直到下一个IDR帧重新刷新图像。</p><p>根据具体的产品的应用场景选择丢帧的解决策略：例如，音视频会议，允许花屏，但总体流畅就OK，共享桌面花屏使得用户观感体验不好，无法看清内容，允许卡顿，但不要花屏。</p><h2 id="4-无损压缩"><a href="#4-无损压缩" class="headerlink" title="4.无损压缩"></a>4.无损压缩</h2><p><strong>整数离散余弦变换（DCT）</strong>，将空间上的相关性变为频域上无关的数据然后进行量化，如图所示，将8x8的宏块数据变换到到角上，方便后续的无损压缩<br><img src="https://img-blog.csdnimg.cn/20210620001013536.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><img src="https://img-blog.csdnimg.cn/20210620001111725.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><p><strong>CABAC压缩</strong></p><p>压缩的原理是利用哈夫曼编码，使用频率高的数据就用小的数据量表示，使用频率低的数据就用大的数据量表示，如图所示为Mpeg2VLC压缩的原理。<br><img src="https://img-blog.csdnimg.cn/20210620001454105.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">        </p><p>在此基础上，CABAC，采用上下文适配的策略，有点类似于帧间压缩参考帧的原理，随着时间的推移，充分利用上下文信息，数据块越来越小，进一步压缩了数据量。</p><p><img src="https://img-blog.csdnimg.cn/20210620001257827.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文只是对H264编码的原理进行了阐释，具体的H264编解码的流程和码流信息，以及H264的分析将会在后面的文章中提到，文中的图片来自于慕课网李超老师的课程以及其他博客的学习资料，在此表示感谢。</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>FFMpeg命令分类</title>
    <link href="/2021/06/04/article2/"/>
    <url>/2021/06/04/article2/</url>
    
    <content type="html"><![CDATA[<p>本文主要介绍FFmpeg的命令分类及基本的使用，具体请参照《FFmpeg从入门到精通》</p><p><img src="https://img-blog.csdnimg.cn/20210603225216334.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="FFmpeg命令分类">  </p><hr><h2 id="1-信息查询命令"><a href="#1-信息查询命令" class="headerlink" title="1.信息查询命令"></a>1.信息查询命令</h2><p><img src="https://img-blog.csdnimg.cn/20210603225327708.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="基本信息查询命令列表"></p><h2 id="2-录制命令"><a href="#2-录制命令" class="headerlink" title="2.录制命令"></a>2.录制命令</h2><p>参数说明<br>-f 设备驱动<br>-i 设备编号</p><h4 id="采集摄像头："><a href="#采集摄像头：" class="headerlink" title="采集摄像头："></a>采集摄像头：</h4><p>根据采集过程中终端中的提示信息按照规定的格式播放。 我的摄像头默认是640x480，25帧，像素格式是yuyv422，使用ffplay播放需要设定正确的参数</p><p>ffmpeg -f video4linux2 -i /dev/video0 out.yuv</p><h4 id="采集桌面："><a href="#采集桌面：" class="headerlink" title="采集桌面："></a>采集桌面：</h4><p>ffmpeg -f x11grab -framerate 25 -video_size 1920x1080 -i :0.0 out.mp4</p><h4 id="采集音频"><a href="#采集音频" class="headerlink" title="采集音频"></a>采集音频</h4><p>ffmpeg -f alsa -i hw:0 out.wav</p><h2 id="3-分解与复用命令"><a href="#3-分解与复用命令" class="headerlink" title="3.分解与复用命令"></a>3.分解与复用命令</h2><p>ffmpeg -i in.mp4 -vcodec copy -acodec copy out.flv</p><p>-an 不要音频数据<br>-vn 不要视频数据</p><h2 id="4-处理原始数据命令"><a href="#4-处理原始数据命令" class="headerlink" title="4.处理原始数据命令"></a>4.处理原始数据命令</h2><h4 id="提取yuv数据："><a href="#提取yuv数据：" class="headerlink" title="提取yuv数据："></a>提取yuv数据：</h4><p>ffmpeg -i input.mp4 -an -c:v rawvideo -pix_fmt yuv420p out.yuv</p><p>-c:v 对视频编码，用原始视频进行编码</p><h4 id="提取PCM数据："><a href="#提取PCM数据：" class="headerlink" title="提取PCM数据："></a>提取PCM数据：</h4><p>ffmpeg -i input.mp4 -vn -ar 44100 -ac2 -f s16le out.pcm</p><p>-ar 音频采样率<br>-ac 声道数<br>-f 数据存储方式</p><h2 id="5-滤镜命令"><a href="#5-滤镜命令" class="headerlink" title="5.滤镜命令"></a>5.滤镜命令</h2><h4 id="视频尺寸修改滤镜"><a href="#视频尺寸修改滤镜" class="headerlink" title="视频尺寸修改滤镜"></a>视频尺寸修改滤镜</h4><p>ffmpeg -i in.mp4 -vf crop=in_w-200:in_h-200 -c:v libx264 -c:a copy out.mp4</p><h2 id="6-裁剪与合并"><a href="#6-裁剪与合并" class="headerlink" title="6.裁剪与合并"></a>6.裁剪与合并</h2><h4 id="裁剪"><a href="#裁剪" class="headerlink" title="裁剪"></a>裁剪</h4><p>ffmpeg -i in.mp4 -ss 00:00:00 -t 10 out.mp4</p><p>-ss 裁剪起始时间<br>-t   裁剪时长</p><h4 id="合并"><a href="#合并" class="headerlink" title="合并"></a>合并</h4><p>ffmpeg -f concat -i inputs.txt out.flv</p><p>-f concat 对后面的文件进行拼接 inputs.txt 内容为 ‘file filename’格式。file内容如下，和裁切片段一个目录下，采用相对路径<br><img src="https://img-blog.csdnimg.cn/20210604124948452.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="file文件内容"></p><h2 id="7-图片与视频命令互转"><a href="#7-图片与视频命令互转" class="headerlink" title="7.图片与视频命令互转"></a>7.图片与视频命令互转</h2><h4 id="视频转图片"><a href="#视频转图片" class="headerlink" title="视频转图片"></a>视频转图片</h4><p> ffmpeg -i outlydy2.mp4 -r 1 -f image2 image-%3d.jpeg</p><p>-r 1 1秒钟一张图片<br>-f image2图片格式 </p><p><img src="https://img-blog.csdnimg.cn/2021060412573361.png" alt="转图片结果"></p><h4 id="图片转视频"><a href="#图片转视频" class="headerlink" title="图片转视频"></a>图片转视频</h4><p>ffmpeg -i image-%3d.jpeg out.mp4 ffplay -r 1 hello.mp4</p><h2 id="8-直播推-拉流"><a href="#8-直播推-拉流" class="headerlink" title="8.直播推/拉流"></a>8.直播推/拉流</h2><h4 id="推流"><a href="#推流" class="headerlink" title="推流"></a>推流</h4><p>ffmpeg -re -i out.mp4 -c copy -f flv rtmp://127.0.0.1/live/livestream</p><p>-re 按时间戳读取文件</p><h4 id="拉流"><a href="#拉流" class="headerlink" title="拉流"></a>拉流</h4><p>拉到本地保存成多媒体文件 </p><p>ffmpeg -i  rtmp://127.0.0.1/live/livestream -c copy live.flv</p><p>ffplay直接观看 </p><p>ffplay rtmp://127.0.0.1/live/livestream</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>FFmpeg编译与依赖库安装</title>
    <link href="/2021/06/03/post1/"/>
    <url>/2021/06/03/post1/</url>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>刚开始学音视频开发，环境的配置研究了几天在几个虚拟机上都尝试了一下，终于把刚开始能踩的坑都踩遍了，遇到了各种问题，经过我的收集整理，把所有遇到的问题都放进来，后面再遇到问题还会继续更新的，作为个人以后参考用，如果写的有错误请各位大佬在评论区指正！感谢很多人帮助了我，希望自己也可以帮助更多的人。<br>我是Ubuntu18.04的版本，不知道是不是版本问题，下的版本好多配置和包都没有，手动配置了好久。</p><h1 id="前期准备工作"><a href="#前期准备工作" class="headerlink" title="前期准备工作"></a>前期准备工作</h1><p>省得之后文件权限问题，都是血和泪的教训啊，记不清在哪个错误的目录下 chmod -R -777 结果sudo su打不开了，为了防止和我一样的错误，先设置一下默认进入root用户，及时备份虚拟机。<br>具体的看这篇，很详细了，感谢这位老哥<br><a href="https://blog.csdn.net/qq_39591507/article/details/81288644">https://blog.csdn.net/qq_39591507/article/details/81288644</a><br>以root身份登陆以后打开shell是这样的<br><img src="https://img-blog.csdnimg.cn/20210420150510445.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">下一步，打开根目录下opt文件夹，新建一个lib文件夹，之后编译的库放里面，后面全部编译完成以后把这个文件夹备份一下<br><img src="https://img-blog.csdnimg.cn/20210420150955569.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">里面我已经编译好了，下载的库资源全部放这里面。</p><h1 id="安装yasm"><a href="#安装yasm" class="headerlink" title="安装yasm"></a>安装yasm</h1><p>直接在刚刚的lib文件夹下面打开终端<br>wget <a href="http://www.tortall.net/projects/yasm/releases/yasm-1.3.0.tar.gz">http://www.tortall.net/projects/yasm/releases/yasm-1.3.0.tar.gz</a><br>tar xvzf yasm-1.3.0.tar.gz<br>cd yasm-1.3.0<br>./configure<br>make &amp;&amp; make install</p><p>PS：//默认的./configure 配置是安装在usr/local/lib里面，后面ffmpeg不放进去，前期的一些必要的组件直接configure没问题。</p><h1 id="安装nasm（2-13以上版本）"><a href="#安装nasm（2-13以上版本）" class="headerlink" title="安装nasm（2.13以上版本）"></a>安装nasm（2.13以上版本）</h1><p>和上面一样<br>wget <a href="https://www.nasm.us/pub/nasm/releasebuilds/2.14.02/nasm-2.14.02.tar.bz2">https://www.nasm.us/pub/nasm/releasebuilds/2.14.02/nasm-2.14.02.tar.bz2</a><br>tar xvf nasm-2.14.02.tar.bz2<br>cd nasm-2.14.02<br>./configure<br>make<br>make install</p><h1 id="安装其他依赖"><a href="#安装其他依赖" class="headerlink" title="安装其他依赖"></a>安装其他依赖</h1><p>apt install cmake -y<br>apt install pkg-config   //后面编译x264和x265需要</p><h1 id="编译x264（只编译静态库）"><a href="#编译x264（只编译静态库）" class="headerlink" title="编译x264（只编译静态库）"></a>编译x264（只编译静态库）</h1><p>x264下载地址：<br><a href="http://ftp.videolan.org/pub/videolan/x264/snapshots/">http://ftp.videolan.org/pub/videolan/x264/snapshots/</a><br>tar xvf x264-snapshot-20191024-2245-stable.tar.bz2<br>cd x264-snapshot-20191024-2245-stable<br>./configure –enable-static –prefix=../x264 –enable-pic<br>make -j<br>make install<br>//make -j4就是开启4个并行编译，make -j不加数字就是默认全部核心数，编译速度差不多要快一半<br>##编译x265（只编译静态库）<br>x265下载地址:<br><a href="http://ftp.videolan.org/pub/videolan/x265/">http://ftp.videolan.org/pub/videolan/x265/</a><br>tar xvf x265_3.2.tar.gz<br>//<strong>和x264编译不一样，264直接在根目录下编译，265要进入这个目录</strong><br>cd x265_3.2/build/linux/        </p><p>cmake -G “Unix Makefiles” -DCMAKE_INSTALL_PREFIX=”../../../x265” -DENABLE_SHARED:bool=off ../../source<br>make -j<br>make install<br>为了避免后面的问题，我们先进行如下的设置<br><img src="https://img-blog.csdnimg.cn/20210420153019777.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>进入265这个目录，编辑一下这个文件<br>按如图添加依赖<br><img src="https://img-blog.csdnimg.cn/20210420153143863.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h1 id="编译SDL2"><a href="#编译SDL2" class="headerlink" title="编译SDL2"></a>编译SDL2</h1><p>编译之前检查一下Ubuntu是否声音输出是否正常，我的是不正常的，基本各种疑难杂症都给我遇见了，不过问题不大，参考一下别人的解决方法。<br><a href="https://blog.csdn.net/multimicro/article/details/82528730">https://blog.csdn.net/multimicro/article/details/82528730</a><br>确保有声音再进入下一步<br>我需要用到ffplay, 需要再下载SDL的源码，<a href="http://libsdl.org/release/">http://libsdl.org/release/</a><br>我的版本是SDL2-2.0.14<br>在编译之前先安装<br>sudo apt-get install libx11-dev<br>sudo apt-get install xorg-dev<br>不然会无法渲染SDL displa<br>如运行ffplay时，有些机器上会出现<br>Could not initialize SDL - No available video device<br>(Did you set the DISPLAY variable?)<br>说明系统中没有安装x11的库文件，因此编译出来的SDL库实际上不能用。</p><p>需要先编译安装SDL，和上面一样，直接默认编译安装</p><p>tar zxvf SDL2-2.0.8.tar.gz</p><p>cd SDL2-2.0.8</p><p>./configure</p><p>make</p><p>make install</p><h1 id="编译ffmpeg"><a href="#编译ffmpeg" class="headerlink" title="编译ffmpeg"></a>编译ffmpeg</h1><p>编译ffmpeg是最后一步，但是前面任何一步配置错误，回去修改以后，ffmpeg都要重新编译。</p><p>ffmpeg直接去官网下载，我下的是4.3.2版本的<br>解压以后还是在lib文件夹里面，我在官网下载的提取出来还套了一个文件夹，直接移到外面来，如图，不然没法直接执行下面的命令<br><img src="https://img-blog.csdnimg.cn/20210420155055789.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">在当前页面打开终端执行<br>export PKG_CONFIG_PATH=$PKG_CONFIG_PATH:../x264/lib/pkgconfig:../x265/lib/pkgconfig</p><p>./configure –enable-shared –enable-nonfree –enable-gpl –enable-pthreads –enable-libx264 –enable-libx265 –prefix=../ffmpeg </p><p>make -j<br>make install</p><p>编译完以后lib文件夹多了这三个</p><p><img src="https://img-blog.csdnimg.cn/20210420165525566.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h1 id="编译ffmpeg-1"><a href="#编译ffmpeg-1" class="headerlink" title="编译ffmpeg"></a>编译ffmpeg</h1><p>编译完成后，进入/etc/profile中将ffmpeg加入到环境变量（在文件最后加上export PATH=/opt/lib/ffmpeg/bin:$PATH）<br><img src="https://img-blog.csdnimg.cn/20210420163102945.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">进一步，把ffmpeg的库加入/etc/ld.so.conf中<br><img src="https://img-blog.csdnimg.cn/20210420163524174.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><h1 id="测试是否安装成功"><a href="#测试是否安装成功" class="headerlink" title="测试是否安装成功"></a>测试是否安装成功</h1><p>执行ffmpeg -devices<br><img src="https://img-blog.csdnimg.cn/20210420160325660.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1Z2VidWN1bw==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">我已经解决了，如果需要alsa驱动的需要装一下alsa驱动</p><p>之前的问题是编译完了ffmpeg发现没有alsa音频驱动，关于如何安装alsa音频驱动建议看这篇<br><a href="https://blog.csdn.net/keepingstudying/article/details/7373246">https://blog.csdn.net/keepingstudying/article/details/7373246</a></p><p>安装完了重启，然后重新编译ffmpeg<br>再测试一下ffplay命令，<br>ffplay xxx.MP4<br>如果可以正常播放视频,声音正常就ok，否则需要重装SDL2，然后重新编译ffmpeg</p><p>主体参考了云天之巅博主的，感谢！<br>具体不清楚的可以看云天之巅博主的视频<br><a href="https://www.bilibili.com/video/BV1Sz411v7Wm">https://www.bilibili.com/video/BV1Sz411v7Wm</a></p><hr>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
